{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "#sparkConf.setMaster(\"spark://127.0.0.1:50345\")\n",
    "sparkConf.setMaster(\"spark://spark-master-svc.lakehouse.svc.cluster.local:7077\")\n",
    "sparkConf.setAppName(\"spark-pi\")\n",
    "#sparkConf.set(\"spark.kubernetes.container.image\", \"docker.io/bitnami/spark:3.5.1-debian-12-r8\")\n",
    "#sparkConf.set(\"spark.kubernetes.namespace\", \"lakehouse\")\n",
    "#sparkConf.set(\"spark.submit.deployMode\", \"client\")\n",
    "#sparkConf.set(\"spark.log.level\", \"ERROR\")\n",
    "#sparkConf.set(\"spark.ssl.enabled\", \"true\")\n",
    "#sparkConf.set(\"spark.driver.host\", \"127.0.0.1\")\n",
    "#sparkConf.set(\"spark.driver.port\", \"30830\")\n",
    "#sparkConf.set(\"spark.kubernetes.driverEnv.SPARK_MASTER_URL\", \"spark://spark-with-ui-master-svc:30830\")\n",
    "#sparkConf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\", \"spark\")\n",
    "#sparkConf.set(\"spark.kubernetes.executor.disableConfigMap\", \"true\")\n",
    "#sparkConf.set(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Zeca','35'), ('Eva', '29')]\n",
    "colNames = ['Nome', 'Idade']\n",
    "\n",
    "df = spark.createDataFrame(data, colNames)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = 'tmp/data.json'\n",
    "games = spark.read.format('json').load(source_path)\n",
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
